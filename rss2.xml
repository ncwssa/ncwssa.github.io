<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>jjHome</title>
    <link>http://example.com/</link>
    
    <atom:link href="http://example.com/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>嘿嘿嘿</description>
    <pubDate>Wed, 06 Nov 2024 00:52:23 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>大数据-4</title>
      <link>http://example.com/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/</link>
      <guid>http://example.com/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/</guid>
      <pubDate>Wed, 06 Nov 2024 00:49:55 GMT</pubDate>
      
        
        
      <description>&lt;h1 id=&quot;大数据-4&quot;&gt;&lt;a href=&quot;#大数据-4&quot; class=&quot;headerlink&quot; title=&quot;大数据-4&quot;&gt;&lt;/a&gt;大数据-4&lt;/h1&gt;&lt;h2 id=&quot;1-HDFS格式化相关问题&quot;&gt;&lt;a href=&quot;#1-HDFS格式化相关问题&quot; class=&quot;header</description>
        
      
      
      
      <content:encoded><![CDATA[<h1 id="大数据-4"><a href="#大数据-4" class="headerlink" title="大数据-4"></a>大数据-4</h1><h2 id="1-HDFS格式化相关问题"><a href="#1-HDFS格式化相关问题" class="headerlink" title="1 HDFS格式化相关问题"></a>1 HDFS格式化相关问题</h2><p>注意：在生产环境中，任何的文件删除几乎都是非常严重的事件。<br>在HDFS有文件存在时是不可以格式化的，因为hdfs格式化仅仅在namenode节点，而数据在其他节点，有文件时格式化会造成namenode的相关id与datanode的不一致，从而进入数据保护模式（安全模式）。<br>如果一定要进行格式化，需要先关闭集群，删除所有节点上的数据目录（在配置文件中指定的），然后进行namenode格式化，再启动集群。<br>一旦提示是安全模式，任何数据操作都进行不了了，需要退出安全模式。</p><h2 id="2-web查看页面"><a href="#2-web查看页面" class="headerlink" title="2 web查看页面"></a>2 web查看页面</h2><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/e6c4fc74b255ec3eb690966b5bbdbe215b39deb7502dced8371229de2f299137.png" alt="图 0">  </p><h2 id="3-HDFS文件上传测试"><a href="#3-HDFS文件上传测试" class="headerlink" title="3 HDFS文件上传测试"></a>3 HDFS文件上传测试</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put 文件名 /</span><br></pre></td></tr></table></figure><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/9638cf631b60bd12704482fef01af6652cfd40bdc184662ae0562c284488d115.png" alt="图 1"><br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/d58fd734de561083f19d85d6282217c1491451e285ea30c984a66f747bfd0e23.png" alt="图 2">  </p><h2 id="4-计算资源测试"><a href="#4-计算资源测试" class="headerlink" title="4 计算资源测试"></a>4 计算资源测试</h2><h3 id="4-1-解决HDFS的所有问题"><a href="#4-1-解决HDFS的所有问题" class="headerlink" title="4.1 解决HDFS的所有问题"></a>4.1 解决HDFS的所有问题</h3><p>文件副本数，默认是3，当前只有2个datanode节点，所以只能存2份，hdfs系统是有冲突的，解决办法：</p><ul><li>把副本数改成1。</li><li>增加一个datanode节点。在实验环境下，可以让namenode节点兼用datanode节点。</li></ul><h3 id="4-2-让namenode节点兼用datanode节点的启动方法"><a href="#4-2-让namenode节点兼用datanode节点的启动方法" class="headerlink" title="4.2 让namenode节点兼用datanode节点的启动方法"></a>4.2 让namenode节点兼用datanode节点的启动方法</h3><h4 id="4-2-1-手动启动"><a href="#4-2-1-手动启动" class="headerlink" title="4.2.1 手动启动"></a>4.2.1 手动启动</h4><p>在namenode节点上启动datanode和nodemanager，命令分别是：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start datanode</span><br><span class="line">yarn --daemon start nodemanager</span><br></pre></td></tr></table></figure><p>启动后，jps情况：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/5db0e748847960d095010f79dfe902b93441d2c49dfa8d784f579bc359bd9108.png" alt="图 6">  </p><h4 id="4-2-2-自动启动"><a href="#4-2-2-自动启动" class="headerlink" title="4.2.2  自动启动"></a>4.2.2  自动启动</h4><p>将namenode的域名写入workers文件，配置分发后，关闭集群，再启动集群。</p><h3 id="4-3-运行mapreduce例程"><a href="#4-3-运行mapreduce例程" class="headerlink" title="4.3 运行mapreduce例程"></a>4.3 运行mapreduce例程</h3><p>运行grep，需要输入文件目录，在集群模式运算，无法使用本地文件系统，必须是hdfs，所以输入文件要保存到hdfs。<br>本地模式运行过程：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/f7277c944c73edfa5d48c6d7b0c7b5c5db65d0dfa55a8c74eab915c4b910f639.png" alt="图 9">  </p><h4 id="4-3-1-准备输入文件"><a href="#4-3-1-准备输入文件" class="headerlink" title="4.3.1 准备输入文件"></a>4.3.1 准备输入文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">本地模式：cp $HADOOP_HOME/etc/hadoop/*.xml input </span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">集群模式：hadoop fs -put $HADOOP_HOME/etc/hadoop/*.xml /input</span><br></pre></td></tr></table></figure><h4 id="4-3-2-运行"><a href="#4-3-2-运行" class="headerlink" title="4.3.2 运行"></a>4.3.2 运行</h4><p>hadoop jar $HADOOP_HOME&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.3.6.jar grep &#x2F;input &#x2F;output ‘dfs[a-z.]+’</p><h4 id="4-3-3-查看运行结果"><a href="#4-3-3-查看运行结果" class="headerlink" title="4.3.3 查看运行结果"></a>4.3.3 查看运行结果</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /output/*</span><br></pre></td></tr></table></figure><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/273c21985669284d6b1a72e1399b5bc878c110dfbc0b87199205c0bdd8f80672.png" alt="图 10">  </p><h2 id="5-hdfs存储原理"><a href="#5-hdfs存储原理" class="headerlink" title="5 hdfs存储原理"></a>5 hdfs存储原理</h2><h3 id="5-1-初始情况"><a href="#5-1-初始情况" class="headerlink" title="5.1 初始情况"></a>5.1 初始情况</h3><h4 id="5-1-1-namenode的存储结构"><a href="#5-1-1-namenode的存储结构" class="headerlink" title="5.1.1 namenode的存储结构"></a>5.1.1 namenode的存储结构</h4><p>具体文件路径：&#x2F;home&#x2F;jj&#x2F;hadoopdata&#x2F;dfs&#x2F;name&#x2F;current<br>当前文件情况：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/6fb8ae49407b0674c8c27dbe6b3369a24e488eef1502502d0141ba1d727b4a1d.png" alt="图 11"><br>删除数据文件，重新namenode格式化，没有启动集群，查看namenode文件系统：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/2e46f0ba7ac80449a957dee5a75c2b6b1650b052111744dc9d7bc8fede7da93a.png" alt="图 12"><br>其他节点没有文件目录。<br>启动集群：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/781c53a38df5c18b83e81e8c5402e938b540759a68f121000d65af62cd463cc0.png" alt="图 13"></p><p>datanode节点的数据目录自动建立，结构是：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/9f0bcee9acdf8c83929e7d01971fc78bf2b152c6291e00507ecbdcae7ed49248.png" alt="图 14">  </p><h4 id="5-1-2-datanode的存储结构"><a href="#5-1-2-datanode的存储结构" class="headerlink" title="5.1.2 datanode的存储结构"></a>5.1.2 datanode的存储结构</h4><p>集群启动后，datanode节点的数据目录自动建立，结构是：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/9f0bcee9acdf8c83929e7d01971fc78bf2b152c6291e00507ecbdcae7ed49248.png" alt="图 14"><br>查看数据目录结构：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/e2269001a91557bfbed5319664e7ef399c97f1a9d6b1610b4741352e6305032c.png" alt="图 15">  </p><h3 id="5-2-存储文件"><a href="#5-2-存储文件" class="headerlink" title="5.2 存储文件"></a>5.2 存储文件</h3><p>为了验证，存储大于一个block（当前配置block是128M）的文件：<br>hadoop fs -put jdk-8u351-linux-x64.tar.gz  &#x2F;<br>web页面查看：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/cb8128a36ea29ca81c0c9aef9063557b32016e81bc3488c5ca4e2ccdb77eb91f.png" alt="图 16"><br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/5d670583fc186d41f10f583df1c9036a46dbc7f2d4706c9257a4f058d9656b3b.png" alt="图 17"><br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/4a93d33e339c270ce2c77660b72ae901ea055a5ee77c7d33547f5a267e10212d.png" alt="图 18"><br>通过Block ID查找文件：<br>在namenode上：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/95bb39ba38a8832a1a8a594351deb19aed12fc1be9f907af0dc51fd80d3c131f.png" alt="图 22"><br>在datanode上：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/d24be7da286abb499157cc50040314f9d6f12c1ca1af6fb13adb89d98c5b4de5.png" alt="图 23"><br>可以看到webUI上显示的block，验证这些block是否是我们上传的文件：<br>验证方法：</p><ul><li><p>将block拷贝出来</p></li><li><p>然后进行组合<br>用追加命令：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/f761b32c2e0a3154d6a91ffe3438bc1a09e1a4804b1b45086371bce7b1d92c30.png" alt="图 19">  </p></li><li><p>再查看文件内容<br>因为当前文件是java压缩包，可以通过解压缩方式然后查看：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/e277f7b5e5f24a8e0179d9c517d0a22d18630d3959ab1cbf0de9da67c71926a0.png" alt="图 20"><br>解压缩没有出错，查看解压缩结果：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/0775d37cafb7926b932a013720f6100c3946dd3bb0ad8da86e904011f0af79a4.png" alt="图 21"></p></li></ul><h2 id="6-hadoop-fs-命令"><a href="#6-hadoop-fs-命令" class="headerlink" title="6 hadoop fs 命令"></a>6 hadoop fs 命令</h2><p>hdfs所有操作一概要求使用绝对路径，就是从&#x2F;开始。</p><h3 id="6-1-远程集群的使用"><a href="#6-1-远程集群的使用" class="headerlink" title="6.1 远程集群的使用"></a>6.1 远程集群的使用</h3><p>可以定义fs.defaultFS来使用，定义方式有两种：（1）修改core-site.xml文件。（2）在fs命令中明确指明文件系统：hadoop -fs <a href="file:///|hdfs://namenode:port">file:///|hdfs://namenode:port</a>。</p><h3 id="6-2-ls"><a href="#6-2-ls" class="headerlink" title="6.2 -ls"></a>6.2 -ls</h3><p>hdfs文件列表。<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/30c5733596cf0fe5fc56d8eb9649198bdfbee19514c248eae3e888067ad55cbb.png" alt="图 24">  </p><h3 id="6-3-put，-copyFromLocal"><a href="#6-3-put，-copyFromLocal" class="headerlink" title="6.3 -put， -copyFromLocal"></a>6.3 -put， -copyFromLocal</h3><p>从本地文件系统拷贝到hdfs。<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/3556be2263349b081ce7c9cc32486fc53932966ca0b17fa5b2e2623c04c8e48a.png" alt="图 26"><br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/96f57f6c92c99a33d371ce4f5dc48703bac78a452c178e882aa7cfb5b4e0f923.png" alt="图 27">  </p><h3 id="6-4-get，-copyToLocal"><a href="#6-4-get，-copyToLocal" class="headerlink" title="6.4 -get， -copyToLocal"></a>6.4 -get， -copyToLocal</h3><p>从hdfs系统拷贝到本地。<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/ac1ba57f0f346592b202efc2d0f6e4f7d6b0af68b91badfcebe0aad9f6bc33f3.png" alt="图 28">  </p><h3 id="6-5-mkdir"><a href="#6-5-mkdir" class="headerlink" title="6.5 -mkdir"></a>6.5 -mkdir</h3><p>在hdfs上创建目录。<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/e6c798129ba91d559f2c8891003a0099ff9dae29f4aba93dcc4837bd6836f1a5.png" alt="图 29">  </p><h3 id="6-6-appendToFile"><a href="#6-6-appendToFile" class="headerlink" title="6.6 -appendToFile"></a>6.6 -appendToFile</h3><p>将本地文件的内容添加到hdfs文件中去。<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/272894e719fad83f43a01751c1caa81935ee0762ef86750f6ec40f990924b17f.png" alt="图 30">  </p><h3 id="6-7-cat"><a href="#6-7-cat" class="headerlink" title="6.7 -cat"></a>6.7 -cat</h3><p>显示hdfs文件内容<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/ab393f887722dc95dbddec71928569bd03b3dc8aee3da7c227a04a7abbf673b8.png" alt="图 31">  </p><h3 id="6-8-其他"><a href="#6-8-其他" class="headerlink" title="6.8 其他"></a>6.8 其他</h3><p>-rm：删除文件或目录。<br>-rmdir：删除空目录。<br>-moveFromLocal：移动本地文件或目录到hdfs。<br>-moveToLocal：移动hdfs文件或目录到本地。<br>-touch：在hdfs上创建一个文件。<br>-cp：hdfs中的拷贝。<br>-mv：hdfs中文件或目录的移动或改名。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/%E5%AD%A6%E4%B9%A0/">学习</category>
      
      
      <category domain="http://example.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</category>
      
      
      <comments>http://example.com/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-4/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>大数据-3</title>
      <link>http://example.com/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/</link>
      <guid>http://example.com/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/</guid>
      <pubDate>Wed, 06 Nov 2024 00:49:51 GMT</pubDate>
      
        
        
      <description>&lt;h1 id=&quot;大数据-3&quot;&gt;&lt;a href=&quot;#大数据-3&quot; class=&quot;headerlink&quot; title=&quot;大数据-3&quot;&gt;&lt;/a&gt;大数据-3&lt;/h1&gt;&lt;h2 id=&quot;hadoop集群部署&quot;&gt;&lt;a href=&quot;#hadoop集群部署&quot; class=&quot;headerlink&quot; </description>
        
      
      
      
      <content:encoded><![CDATA[<h1 id="大数据-3"><a href="#大数据-3" class="headerlink" title="大数据-3"></a>大数据-3</h1><h2 id="hadoop集群部署"><a href="#hadoop集群部署" class="headerlink" title="hadoop集群部署"></a>hadoop集群部署</h2><h3 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1 基本概念"></a>1 基本概念</h3><h4 id="1-1-namenode，datanode"><a href="#1-1-namenode，datanode" class="headerlink" title="1.1 namenode，datanode"></a>1.1 namenode，datanode</h4><p>是HDFS（分布式文件系统）中的概念。</p><ul><li>namenode：名字节点，保存的是文件系统树形结构和文件内容存储位置、校验码等相关信息，不保存文件的具体内容。namenode在标准模式下只有一个，存在单点故障问题，如果此节点崩溃了，整个HDFS系统文件都很难找回；为了避免这种情况，可以配置高可用集群（HA）。</li><li>datanode：按照namenode的指定，保存文件的具体内容的一部分。默认每一个文件数据块是保存三个副本，在三个不同的datanode节点上。</li><li>SecondaryNameNode：第二个名字节点，但不是namenode的同步备份，是namenode的延时备份，延时时间与系统设置和系统负载有关。</li></ul><h4 id="1-2-ResourceManager，NodeManager"><a href="#1-2-ResourceManager，NodeManager" class="headerlink" title="1.2 ResourceManager，NodeManager"></a>1.2 ResourceManager，NodeManager</h4><ul><li>ResourceManager：资源管理器，负责整个集群的资源管理，包括存储资源和计算资源，一个集群只能有一个在运行状态。存在单点故障问题，解决办法是配置高可用集群（HA）</li><li>NodeManager：节点管理，只负责本节点的资源。</li><li>一般情况下，master节点部署ResourceManager，其他节点部署NodeManager，所有节点都需要有管理进程。</li></ul><h3 id="2-配置文件目录管理和编辑工具安装"><a href="#2-配置文件目录管理和编辑工具安装" class="headerlink" title="2 配置文件目录管理和编辑工具安装"></a>2 配置文件目录管理和编辑工具安装</h3><h4 id="2-1-选择vscode-下载-安装"><a href="#2-1-选择vscode-下载-安装" class="headerlink" title="2.1 选择vscode,下载,安装"></a>2.1 选择vscode,下载,安装</h4><p>安装：sudo apt install .&#x2F;code_1.94.2-1728494015_amd64.deb<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/3e6090986569474aa0a08870d31ce0413eca713eaad684f7f6120176a60423ed.png" alt="图 1">  </p><h3 id="2-2-配置文件目录"><a href="#2-2-配置文件目录" class="headerlink" title="2.2 配置文件目录"></a>2.2 配置文件目录</h3><p>根目录：两个子目录：readOnly，specific，然后拷贝文件到目录中。<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/7862ccf5f7af6c0e02292ac9cbbfa93ac775b1287424ef0eb52048baeb9613b0.png" alt="图 2">  </p><h3 id="3-hadoop集群配置"><a href="#3-hadoop集群配置" class="headerlink" title="3 hadoop集群配置"></a>3 hadoop集群配置</h3><h4 id="3-1-hadoop-env-sh"><a href="#3-1-hadoop-env-sh" class="headerlink" title="3.1 hadoop-env.sh"></a>3.1 hadoop-env.sh</h4><p>配置相关目录，目的是解决读写选项权限问题。<br>目前增加的配置内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_PID_DIR=/home/jj/hadoopdata/HADOOP_PID_DIR</span><br><span class="line">export HADOOP_LOG_DIR=/home/jj/hadoopdata/HADOOP_LOG_DIR</span><br></pre></td></tr></table></figure><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/cc5f15acc609948fdf97dc9a0dcc2bb6c53c99f1421c852c0c990c77d7711879.png" alt="图 4">  </p><h4 id="3-2-core-site-xml"><a href="#3-2-core-site-xml" class="headerlink" title="3.2 core-site.xml"></a>3.2 core-site.xml</h4><p>官方手册要求配置：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/80c455931970c78c6c8022cbd7edf6758ce9c05e853bda5c9a28ef8265a9223a.png" alt="图 5"><br>配置内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;hdfs://master:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;io.file.buffer.size&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;131072&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/90ff112cde7775df545cbec1151393484268f34a49e1d91be895478d0abd41ea.png" alt="图 6">  </p><h4 id="3-3"><a href="#3-3" class="headerlink" title="3.3"></a>3.3</h4><h5 id="3-3-1-namenode配置"><a href="#3-3-1-namenode配置" class="headerlink" title="3.3.1 namenode配置"></a>3.3.1 namenode配置</h5><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/8cdaacf7e6bb849a207344ca665a2e5499d2d256e3869f57f746af0568ed9aad.png" alt="图 7">  </p><ul><li>dfs.namenode.name.dir：持久化名字空间和传送日志。可以用以逗号分隔的路径，这样每个路径都保存一个副本，作为冗余。<br>readOnly文件配置内容：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/fde20796374b636bae8e5732eead06facbfcad6fc8cea7ad2e9359513e6a6c61.png" alt="图 11"><br>指向了一个变量file:&#x2F;&#x2F;${hadoop.tmp.dir}&#x2F;dfs&#x2F;name构成的路径，查看变量和引用：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/875f81a62461f6ecef9e08c30151ea6ebbc8040a85cc5881401d56b9f82dc52e.png" alt="图 12"><br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/028919d4f00bc7f8ca69faf72d06f0197b6f1e94066afd5fdfe4df5f6afa5878.png" alt="图 13"><br>本变量被很多配置文件引用，所以修改本变量内容是比较合理且简单的办法：<br>本变量的定义位置在core-default.xml，所以我们将变量定义到core-site.xml：<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/jj/hadoopdata<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>A base for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>当前core-site.xml内容：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/5c001b8c279d5c831a07d05ee00825dc20d8d0c08d116806a7d51cd1f9f54971.png" alt="图 14"><br>系统允许时，本配置形成的路径是：file:&#x2F;&#x2F;&#x2F;home&#x2F;jj&#x2F;hadoopdata&#x2F;dfs&#x2F;name，在namanode节点上。</li><li>dfs.hosts &#x2F; dfs.hosts.exclude：设置允许的&#x2F;不允许的datanode，根据需要设置，我们不设置了。</li><li>dfs.blocksize：文件存储时块大小。系统建议使用256M。readonly文件的配置是128M，我们实验时，数据文件一般不大，所以没有必要设置大的blocksize，相反，为了减少磁盘无效占用，可以适当减小blocksize。<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/c8191653fedcc41c9fa0e14277b2a64f866db9eaefff33c342d86fb8205fffa0.png" alt="图 8">  </li><li>dfs.namenode.handler.count：readonly文件的配置是10，维持不变，本文件不配置此项。<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/2a7c39dad35b553851d1f7219dfa732d7819cdcd59f00dff66fea6f6111c8d98.png" alt="图 9"></li></ul><h5 id="3-3-2-datanode配置"><a href="#3-3-2-datanode配置" class="headerlink" title="3.3.2 datanode配置"></a>3.3.2 datanode配置</h5><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/de4a6c828a8ce0cddbe56824053b23f5eb3628816ada49f93402568570bc1de0.png" alt="图 15"><br>readOnly文件中的默认配置是：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/0d8ae54a40e1c09e8b85936109cde8cf188aaf5b56bd67007c742dbc02fcce51.png" alt="图 16"><br>因为我们已经在core-site.xml中重新定义了变量hadoop.tmp.dir，所以本项不同配置了。<br>系统允许时，本配置形成的路径是：file:&#x2F;&#x2F;&#x2F;home&#x2F;jj&#x2F;hadoopdata&#x2F;dfs&#x2F;data，在datanode节点上。<br>综上：本文件当前没有配置内容。</p><h4 id="3-4-yarn-site-xml"><a href="#3-4-yarn-site-xml" class="headerlink" title="3.4 yarn-site.xml"></a>3.4 yarn-site.xml</h4><p>yarn作hadoop集群的资源管理。<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/7c4cb8e02c251f3a94e06036094d69edbff6dfbde1ed35bf346f0bfcaa2a07cb.png" alt="图 17"><br>以上保持默认。<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/a66e6ff6531b87bbd623a8517bac453be18e0164e0da6fd9893bba0143494fd1.png" alt="图 18"><br>通过分析，需要配置yarn.resourcemanager.hostname，需要核实配置yarn.resourcemanager.scheduler.class。<br>检查yarn.resourcemanager.hostname的默认配置在yarn-default.xml：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/5667015158bb26d28ab3e7a46bee5687c5410a445c37921fddb17693a9eaf3d0.png" alt="图 19"><br>默认指向0.0.0.0，即在每个节点上都启动resourcemanager，单一个集群只能有一个resourcemanager，所以必须设置，可以任选一个节点，例如master。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>The hostname of the RM.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br></pre></td></tr></table></figure><p>yarn.resourcemanager.scheduler.class的默认配置：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/e567d3622dbfa19e4fced793fdd3ee67b83139a57bcc3d4c9ce6cc7a698197e7.png" alt="图 20"><br>已经按照推荐配置了。<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/550643974ecd724ce6e381be208454b5fdd782c550af82ba395d4715d814aad7.png" alt="图 22"><br>通过分析，需要配置yarn.nodemanager.local-dirs、yarn.nodemanager.log-dirs和yarn.nodemanager.remote-app-log-dir，核实配置yarn.nodemanager.aux-services。<br>查看默认配置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>List of directories to store localized files in. An </span><br><span class="line">    application&#x27;s localized file directory will be found in:</span><br><span class="line">    $&#123;yarn.nodemanager.local-dirs&#125;/usercache/$&#123;user&#125;/appcache/application_$&#123;appid&#125;.</span><br><span class="line">    Individual containers&#x27; work directories, called container_$&#123;contid&#125;, will</span><br><span class="line">    be subdirectories of this.</span><br><span class="line"> <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.local-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;hadoop.tmp.dir&#125;/nm-local-dir<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>指向的变量我们已经在core-site.xml中定义了，所以本项不用配置了。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">    Where to store container logs. An application&#x27;s localized log directory</span><br><span class="line">    will be found in $&#123;yarn.nodemanager.log-dirs&#125;/application_$&#123;appid&#125;.</span><br><span class="line">    Individual containers&#x27; log directories will be below this, in directories </span><br><span class="line">    named container_&#123;$contid&#125;. Each container directory will contain the files</span><br><span class="line">    stderr, stdin, and syslog generated by that container.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.log-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.log.dir&#125;/userlogs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>yarn.nodemanager.log-dirs用到了${yarn.log.dir}，此变量没有定义，本项需要配置。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Where to aggregate logs to.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>yarn.nodemanager.remote-app-log-dir指向&#x2F;tmp&#x2F;logs，因为写权限问题，需要重新定义。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>A comma separated list of services where service name should only</span><br><span class="line">    contain a-zA-Z0-9_ and can not start with numbers<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!--&lt;value&gt;mapreduce_shuffle&lt;/value&gt;--&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>yarn.nodemanager.aux-services没有定义，所以需要设置，将注释取消。</p><p>本部分的配置：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/74f8cacb50d66ff3f5c24669ec913a7ea703bba57c453612fd910205cb1fb591.png" alt="图 23">  </p><h4 id="3-5-mapred-site-xml"><a href="#3-5-mapred-site-xml" class="headerlink" title="3.5 mapred-site.xml"></a>3.5 mapred-site.xml</h4><p>要求配置内容：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/0ed9ab8f3365a744ce73bfeaaf0b8422770936317451be7ef2b12c748e27697f.png" alt="图 24">  </p><p>需要配置三项：<br>mapreduce.framework.name，mapreduce.jobhistory.intermediate-done-dir，mapreduce.jobhistory.done-dir。</p><p>（1）mapreduce.framework.name的默认配置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>local<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The runtime framework for executing MapReduce jobs.</span><br><span class="line">  Can be one of local, classic or yarn.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>需要将配置修改为yarn。</p><p>（2）mapreduce.jobhistory.intermediate-done-dir的默认配置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.intermediate-done-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.app.mapreduce.am.staging-dir&#125;/history/done_intermediate<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span><span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>指向了变量${yarn.app.mapreduce.am.staging-dir}，查看此变量设置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.staging-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/hadoop-yarn/staging<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The staging dir used while submitting jobs.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>指向了&#x2F;tmp&#x2F;hadoop-yarn&#x2F;staging，会有写权限问题，需要设置。</p><p>（3）mapreduce.jobhistory.done-dir的默认配置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.done-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;yarn.app.mapreduce.am.staging-dir&#125;/history/done<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span><span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>通过变量${yarn.app.mapreduce.am.staging-dir}进行设置，因为上一步已经设置了此变量，所以可以不用设置了。<br>总结：需要设置两项，如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The runtime framework for executing MapReduce jobs.</span><br><span class="line">  Can be one of local, classic or yarn.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.staging-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;hadoop.tmp.dir&#125;/hadoop-yarn/staging<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>The staging dir used while submitting jobs.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/b9905c4b23f2d6db36ef5a1b64ac886d89125902d08df35d375400bd65d155eb.png" alt="图 25">  </p><h4 id="3-6-workers"><a href="#3-6-workers" class="headerlink" title="3.6 workers"></a>3.6 workers</h4><p>在此文件中写入datanode的域名（注意：必须是域名），每行一个，在用脚本启动时，会读取此文件，进行批量启动。<br>先写两个到workers：<br>slave0<br>slave1</p><h4 id="3-7-分发"><a href="#3-7-分发" class="headerlink" title="3.7 分发"></a>3.7 分发</h4><p>编写分发脚本。<br>所有节点的hadoop相关文件路径都要相同。<br>分发脚本分为软件分发和配置分发。</p><ul><li>软件分发：将主节点的软件分发到其他所有节点，分发脚本的主要命令是scp，分发脚本内容：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;distribute begin&quot;</span><br><span class="line">echo &quot;distribute software to slave0&quot;</span><br><span class="line">scp -r ~/software slave0:~</span><br><span class="line">echo &quot;distribute software to slave1&quot;</span><br><span class="line">scp -r ~/software slave1:~</span><br><span class="line">echo &quot;distribute end&quot;</span><br></pre></td></tr></table></figure><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/dfd0b426fccb2289145931473f8d84940c184467009c4ebb99e34a82f4e7c530.png" alt="图 26"><br>注意事项：观察分发过程，解压缩后的文件在scp过程中可能会有问题，如果有问题，scp压缩包，在节点上解压。</li><li>配置分发：包括系统环境配置（.bashrc）和hadoop配置</li><li><ul><li>系统环境配置（.bashrc）：如果所有节点都是同构的（操作系统完全相同），可以直接分发.bashrc文件；如果是异构的，只能将配置内容拷贝。</li></ul></li><li><ul><li>hadoop配置：通过编写分发脚本，直接分发。<br>分发脚本文件内容：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;distribute begin&quot;</span><br><span class="line">echo &quot;distribute master&quot;</span><br><span class="line">scp specific/* master:$&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line">echo &quot;distribute slave0&quot;</span><br><span class="line">scp specific/* slave0:$&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line">echo &quot;distribute slave1&quot;</span><br><span class="line">scp specific/* slave1:$&#123;HADOOP_HOME&#125;/etc/hadoop</span><br><span class="line">echo &quot;distribute end&quot;</span><br></pre></td></tr></table></figure><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/5f5f627861667daa4ea2f3f518a6d2906afd204caa142b4b7bedca2a6b8f1f38.png" alt="图 27"></li></ul></li></ul><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/4320c4688f2ef92d38f1b69a0ca17c97d50131775b4f8bb12a4771ea5d8a07e1.png" alt="图 29">  </p><h3 id="4-集群启动"><a href="#4-集群启动" class="headerlink" title="4 集群启动"></a>4 集群启动</h3><p>需要启动HDFS和yarn</p><h4 id="4-1-格式化"><a href="#4-1-格式化" class="headerlink" title="4.1 格式化"></a>4.1 格式化</h4><p>第一次启动HDFS之前必须进行格式化，而且只能进行一次，如果进行第二次格式化，就会因为文件系统的某些id不同，进入数据保护模式（安全模式）。在安全模式下，是不能对数据进行任何操作的。<br>启动集群之前的格式化是初始化文件系统，只是在namenode上；一旦启动集群，namenode将会把文件系统的初始化信息传递到所有节点。<br>注意：HDFS格式化只能在namenode节点上执行。<br>格式化之前家目录截图：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/763f8c61cc601314c4ef091a7cc8b558a588e9af7d7f36fe1e294b68a85166f9.png" alt="图 28"><br>格式化命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure><p>格式化成功的提示：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/10a37483bc6d02463e0015a23785fede0230f1d677c95438db3683474ef4c50a.png" alt="图 30"><br>创建了一个路径：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/c8c8cdcb6329adece694a88a0b1d14930598d595046719584bf29b2e01645619.png" alt="图 31">  </p><h4 id="4-2-集群启动和关闭"><a href="#4-2-集群启动和关闭" class="headerlink" title="4.2 集群启动和关闭"></a>4.2 集群启动和关闭</h4><p>按照我们的配置，如果使用如下脚本，集群启动和关闭只能在namenode上执行。<br>在workers文件和ssh免密配置好的情况下，执行如下命令启动HDFS：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure><p>观察master的java进程：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/2ac2f097300a95e565831c76fd7d40331736f50aa48db13ca79df5135af38139.png" alt="图 32"><br>master上有namenode进程和scondarynamenode进程，说明namenode启动正常。<br>观察slave0的java进程：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/0c265f0e995d6b6b95ee4348ddb35bd2688325567eee59b7087390aeb701fcf0.png" alt="图 33"><br>观察slave1的java进程：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/7aa18bb16bfae20d53670f8f83e86237c86f779a31baa400aac266ad385a64fa.png" alt="图 34"><br>slave0和slave1都有datanode进程，说明启动正常。<br>启动yarn：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/ba871a7bcb293f7fd2df13eb347b03e083e67db5be4431af55fffa280bd1df3f.png" alt="图 35"><br>master节点上应该增加一个resourcemanager进程，datanode节点上应该增加了nodemanager进程，通过jps观察：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/54ab13ba535557b613920ec83944839b77c33c52884b97a07589ec5de3750a2a.png" alt="图 36"><br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/6b5821e7392f7d5fbd7512cd5db69ed21ba1d11cda9edcc06bc583244bf13921.png" alt="图 37"><br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/846cd5843d806a9f20f905095d8657588949fce7f144d916c1916fd62ab39c1f.png" alt="图 38">  </p><p>关闭过程：stop-yarn.sh 和 stop-dfs.sh<br>stop-yarn.sh：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/241e3f0c521739635571a0ef3b13f60eb02b7ae01b2ae98ae451fd8e7d807ad1.png" alt="图 39"><br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/e573a83a563a5c9025010bb4ff0af8a0ed83aa8c900df4121210e4490db81bc9.png" alt="图 40"><br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/66693489a6c8bbc5c2d42609dff527c02e8465b24698ba4a459826389c248866.png" alt="图 41"><br>stop-dfs.sh：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/eeee14dbe53382a0ddb06f00ac0d036ce06cf38c89d55331589e7c797c2a2939.png" alt="图 42"><br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/4e3b62f43b5e37f3f4d3377cea09112138a7daef82d7182a63b892cb9d6b20d2.png" alt="图 43"><br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/31c4ba6142a6984d2087108c243fc4609df4a2f917441f2e5b52370ea6af8f9f.png" alt="图 44">  </p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/%E5%AD%A6%E4%B9%A0/">学习</category>
      
      
      <category domain="http://example.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</category>
      
      
      <comments>http://example.com/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-3/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>大数据-2</title>
      <link>http://example.com/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/</link>
      <guid>http://example.com/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/</guid>
      <pubDate>Wed, 06 Nov 2024 00:39:25 GMT</pubDate>
      
        
        
      <description>&lt;h1 id=&quot;大数据-2&quot;&gt;&lt;a href=&quot;#大数据-2&quot; class=&quot;headerlink&quot; title=&quot;大数据-2&quot;&gt;&lt;/a&gt;大数据-2&lt;/h1&gt;&lt;h2 id=&quot;1-安装Java8&quot;&gt;&lt;a href=&quot;#1-安装Java8&quot; class=&quot;headerlink&quot; ti</description>
        
      
      
      
      <content:encoded><![CDATA[<h1 id="大数据-2"><a href="#大数据-2" class="headerlink" title="大数据-2"></a>大数据-2</h1><h2 id="1-安装Java8"><a href="#1-安装Java8" class="headerlink" title="1.安装Java8"></a>1.安装Java8</h2><p>Linux下软件安装方法：</p><ul><li>（1）通过apt库安装：安装命令：sudo apt install 软件名；<br>优点：方便；缺点：很有可能是简化版的。 </li><li>（2）通过安装脚本安装：先下载安装脚本，然后安装；<br>优点：比较方便；缺点：安装脚本找不到，软件安装内容也有可能不全。</li><li>（3）手动安装：下载二进制软件包，配置。<br>优点：所有功能都可以自己把握；缺点：非常麻烦。</li><li>（4）源码安装：下载源代码和相关依赖。编译、安装。</li></ul><h3 id="1-2-下载"><a href="#1-2-下载" class="headerlink" title="1.2 下载"></a>1.2 下载</h3><p>下载Java8全功能二进制软件包：jdk-8u351-linux-x64.tar.gz。(.tar表示打包过，.gz表示压缩过)<br>解压缩：z是压缩格式，x指解压.tar，vf是把解压缩的过程显示出来</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf 包名</span><br></pre></td></tr></table></figure><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/e9ac58b6f6ace4b70f997722d3027869f71dc119fa361de23467e10de3c848d9.png" alt="图 5"><br>测试：<br>进入软件入口执行文件所在路径，全路径执行入口可执行文件：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/ec948da103a8cecc2328ba8d068d1754d50b68c2be25ae129daea6ab43f3756b.png" alt="图 6"><br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/7e7627cb782e08e8e4f84aa3dd2150ccbc0e9748d339378f86784dfbbd7e13bf.png" alt="图 7">  </p><h3 id="1-3-配置环境"><a href="#1-3-配置环境" class="headerlink" title="1.3 配置环境"></a>1.3 配置环境</h3><p>配置环境变量：JAVA_HOME；将Java可执行文件路径配置到环境变量PATH。<br>为了减少对系统的影响，配置到本用户下，就是只对本用户生效。<br>配置到本用户的.bashrc中。先备份一个，然后编辑：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp .bashrc bashrc_bak</span><br></pre></td></tr></table></figure><p>检查root用户能否登录，以防止配置文件改坏后无法修复。<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/2c74dd53e9d5051224ac26a5144ac9b283d79ad37179e8d60faf9758f7dec625.png" alt="图 8">  </p><p>编辑.bashrc：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim .bashrc</span><br></pre></td></tr></table></figure><p>添加如下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">my</span></span><br><span class="line">export JAVA_HONE=/home/jj/software/jdk1.8.0_351</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/99e05ea9632e285a1a99b2d8a3ba8041cd7714d1054d1d6321c578a4fe7f0482.png" alt="图 9"><br>保存退出后，打开一个新终端或者本终端中重新装载.bashrc文件（source .bashrc 或 . .bashrc），验证：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/68df7271102f2482668c7f0092f66297a595b27ad66f41cde0bf56a0cc1a1a6f.png" alt="图 10">  </p><h3 id="1-4-其他节点"><a href="#1-4-其他节点" class="headerlink" title="1.4 其他节点"></a>1.4 其他节点</h3><p>从当前节点远程拷贝Java程序文件，然后配置路径。<br>远程拷贝Java程序文件（需要新建software文件夹）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r $JAVA_HOME slave0:/home/jj/software/jdk1.8.0_351</span><br><span class="line">scp -r $JAVA_HOME slave0:/home/jj/software/jdk1.8.0_351</span><br></pre></td></tr></table></figure><p>将已经配置好的.bashrc对应内容拷贝到其他节点对应的.bashrc中。</p><h2 id="2-安装Hadoop"><a href="#2-安装Hadoop" class="headerlink" title="2 安装Hadoop"></a>2 安装Hadoop</h2><p>安装方法：下载，配置路径。</p><h3 id="2-1-解压缩"><a href="#2-1-解压缩" class="headerlink" title="2.1 解压缩"></a>2.1 解压缩</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -z -zxvf 包名</span><br></pre></td></tr></table></figure><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/68622bafdc43e0e8b0d327f5ed766e2978f6a39d9f1d79112e2fc35198e212dd.png" alt="图 11">  </p><h4 id="2-1-1-测试"><a href="#2-1-1-测试" class="headerlink" title="2.1.1 测试"></a>2.1.1 测试</h4><p>找到可执行入口文件,执行：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/1ad395c0d1bed6fd8f713715f05c04aa86164b21a39f49760ab9c31ad84acae1.png" alt="图 13">  </p><h3 id="2-2-配置环境变量"><a href="#2-2-配置环境变量" class="headerlink" title="2.2 配置环境变量"></a>2.2 配置环境变量</h3><p>需要配置两个内容：HADOOP_HOME，再PATH中添加可执行文件路径：bin和sbin。<br>配置到.bashrc.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/home/jj/software/hadoop-3.3.6</span><br><span class="line">export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</span><br></pre></td></tr></table></figure><p><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/a05880e8ab5457b2c77513de906bb461154cfefc256401680c5188372bc5b0dd.png" alt="图 14"><br>配置后，使配置生效（新开一个终端，或者本终端中执行source .bashrc（或者. .bashrc）），测试：<br><img src="/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/09de737f156e338299663b6ae8be003aa806ddfdd8b4edb991be037e6922a58b.png" alt="图 15">  </p><h3 id="2-3-单节点Hadoop应用"><a href="#2-3-单节点Hadoop应用" class="headerlink" title="2.3 单节点Hadoop应用"></a>2.3 单节点Hadoop应用</h3><p>单节点有两种方式：local模式（单进程），伪集群（通过多个进程模拟多个节点）。我们只配置local模式，因为debug程序一般是在此模式下。<br>配置内容：<br>在$HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;hadoop-env.sh中配置JAVA_HOME变量，指向本机的java根路径。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/home/jj/software/jdk1.8.0_351</span><br></pre></td></tr></table></figure><p>运行官方教程，验证hadoop：</p><ul><li>创建路径：<br>mkdir input</li><li>拷贝hadoop配置文件路径下的所有.xml结尾的文件：<br>cp $HADOOP_HOME&#x2F;etc&#x2F;hadoop&#x2F;*.xml input</li><li>用hadoop例程查找所有dfs开头的全是字母的内容并写入到output路径下：<br>hadoop jar $HADOOP_HOME&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.3.6.jar grep input output ‘dfs[a-z.]+’</li><li>查看结果：<br>cat output&#x2F;*</li></ul>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/%E5%AD%A6%E4%B9%A0/">学习</category>
      
      
      <category domain="http://example.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</category>
      
      
      <comments>http://example.com/2024/11/06/%E5%A4%A7%E6%95%B0%E6%8D%AE-2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>大数据-1</title>
      <link>http://example.com/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/</link>
      <guid>http://example.com/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/</guid>
      <pubDate>Mon, 04 Nov 2024 14:17:52 GMT</pubDate>
      
        
        
      <description>&lt;h1 id=&quot;大数据-1&quot;&gt;&lt;a href=&quot;#大数据-1&quot; class=&quot;headerlink&quot; title=&quot;大数据-1&quot;&gt;&lt;/a&gt;大数据-1&lt;/h1&gt;&lt;h2 id=&quot;1-安装必要的软件&quot;&gt;&lt;a href=&quot;#1-安装必要的软件&quot; class=&quot;headerlink&quot; ti</description>
        
      
      
      
      <content:encoded><![CDATA[<h1 id="大数据-1"><a href="#大数据-1" class="headerlink" title="大数据-1"></a>大数据-1</h1><h2 id="1-安装必要的软件"><a href="#1-安装必要的软件" class="headerlink" title="1.安装必要的软件"></a>1.安装必要的软件</h2><ol><li>选择软件源<br>点击左下角软件，选择Softeare &amp; Updates图标<br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/0624e1e454dd1ecc52df846d3598e5283ca5f0d14d325f409b537e4e7289621f.png"></li></ol><p><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/4c1b4977ed7db92a25b07b187ebef3b952b817b9a0bf9ce9ec521f811a41ed0c.png">  </p><ol><li><p>设置root密码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo passwd root</span><br></pre></td></tr></table></figure><p><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/5f49483ad5058743c026ed4dc1d3369ebc1a55bb7ed500d457ab7c0a62ca0742.png">  </p></li><li><p>安装编辑器vim<br>开启一个终端窗口：桌面空白处右键选择打开一个终端，或者快捷键：Ctrl+Alt+t<br>然后在窗口中执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install vim</span><br></pre></td></tr></table></figure><p><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/9da029738531cf2d88d0a6e0450803eaaab34ba0d5448372033268250e7141e7.png">  </p></li><li><p>安装openssh-server<br>ssh是一种远程登陆的方式（协议）,使用非对称密钥。ubuntu desktop默认安装了openssh-client,没有安装openssh-server.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install openssh-server</span><br></pre></td></tr></table></figure><p><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/08ca80b1bed0d24a442b3be2bf0e76e34b4c1704a3caa4a814ac557e18d5c65a.png">  </p></li><li><p>设置网络<br>分两种情况：</p></li></ol><ul><li>每台host运行一台ubuntu，由多台host运行的虚拟机组成集群。</li><li>一台host运行多个虚拟机。<br>本次采用第二种情况。<br>（1）网络只能使用桥接模式（第二层网络）。<br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/63f020c7fc93ca94dfe6d9b4000d3cbfc0519f09314057ab7b9913658a23ae3a.png" alt="图 0"><br>设置IP地址：<br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/ed298e23b46e6f98dd7831703af7a3fc4ee31d7c3b1f185974443be17bf4ae97.png" alt="图 1"></li></ul><p>（2）建议网络使用NAT模式（第三层网络）。<br>打开三个虚拟机，网络都设置为NAT模式：<br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/f7f9b26e16d5491efa90b20c50247285a69b18f696f7d37091c2f8d25acf1b86.png" alt="图 2"><br>查看每个虚拟机的IP地址：<br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/466ffe434e1fad4da5c71386e13ecab6969b56e49e711608969ef1ef9f6eb5d1.png" alt="图 3">  </p><p><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/1284a6201511e6fd0d08b7478c9e1d755606271220ddbcb4b4e2a40eb6fe84b0.png" alt="图 4">  </p><p>设置固定的IP地址，对于server版ubuntu，需要通过配置文件进行设置，文件位置&#x2F;etc&#x2F;netplan，再进入对应文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">This is the network config written by <span class="string">&#x27;subiquity&#x27;</span></span></span><br><span class="line">network:</span><br><span class="line">  ethernets:</span><br><span class="line">    ens33:</span><br><span class="line">      dhcp4: no</span><br><span class="line">      addresses:</span><br><span class="line">        - 192.168.118.7/24</span><br><span class="line">      gateway4: 192.168.118.2</span><br><span class="line">      nameservers:</span><br><span class="line">        addresses: [172.16.3.8, 114.114.114.114]</span><br><span class="line">  version: 2</span><br></pre></td></tr></table></figure><p>使配置生效</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo netplan apply</span><br></pre></td></tr></table></figure><p>检查ip地址，检查所有节点的双向网络连接情况。</p><h2 id="3-配置Hadoop集群"><a href="#3-配置Hadoop集群" class="headerlink" title="3 配置Hadoop集群"></a>3 配置Hadoop集群</h2><h3 id="1）节点准备"><a href="#1）节点准备" class="headerlink" title="1）节点准备"></a>1）节点准备</h3><h4 id="（1）配置网络"><a href="#（1）配置网络" class="headerlink" title="（1）配置网络"></a>（1）配置网络</h4><p>首先有三个以上的网络已经连通的节点。配置计算机名和域名解析。<br>Hadoop程序会把计算机名当成域名来用，所以计算机名和域名必须一致。<br>网络连通的验证方法：</p><ul><li>从master：ping slave0的ip；ping slave1的ip</li><li>从slave0：ping master的ip；ping slave1的ip</li><li>从slave1：ping master的ip；ping slave0的ip</li><li>B）配置计算机名<br>每个节点计算机名称选择：例如master、slave0、slave1.<br>计算机名配置文件：&#x2F;etc&#x2F;hostname，文件中的内容就是计算机名。<br>编辑所有节点的&#x2F;etc&#x2F;hostname，写入选择的计算机名，不能重名。</li></ul><p>C）配置域名解析<br>（1）本地域名文件：hosts。所有节点写入相同的全部节点的域名解析。文件位置：&#x2F;etc下。<br>编辑hosts文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/hosts</span><br></pre></td></tr></table></figure><p>对master节点：<br>删除有冲突的域名<br>添加如下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">my hosts</span></span><br><span class="line">192.168.118.6   master</span><br><span class="line">192.168.118.7   slave0</span><br><span class="line">192.168.118.129 slave1</span><br></pre></td></tr></table></figure><p>编辑完之后验证：<br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/76fac6da32d35edc6f9084cf4d7514b4a7a940f3132ea02de2e29ecb3091b1ca.png" alt="图 0"><br>分别远程登陆slave0和slave1，拷贝同样域名内容。<br>用域名验证网络连接。</p><h4 id="（2）ssh连接免密配置"><a href="#（2）ssh连接免密配置" class="headerlink" title="（2）ssh连接免密配置"></a>（2）ssh连接免密配置</h4><p>免密配置分两步：</p><ol><li>产生密钥对；<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure></li><li>传送公钥到所有节点（包括自己）。<br>如果产生密钥对的过程中全部用默认，可以使用如下命令传送：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id 传送节点</span><br></pre></td></tr></table></figure></li></ol><ul><li><p>从master开始<br>生成密钥对：<br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/3fca7e9b85971cb4ce77a3a6a2be1b83f11d7ad8a80992970be3d4992414304e.png" alt="图 1">  </p></li><li><p>传送公钥到所有节点（当前有三个节点）：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id master</span><br><span class="line">ssh-copy-id slave0</span><br><span class="line">ssh-copy-id slave1</span><br></pre></td></tr></table></figure></li><li><p>然后在其他两个节点进行相同的操作。</p></li></ul><p>验证：从三个节点用ssh登陆其他节点都不需要密码了<br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/002ab752f7fc0ceec9b598c05877b972c9223cc3c924aa0e17408ad229ce27b1.png" alt="图 2">  </p><h4 id="（3）时钟同步"><a href="#（3）时钟同步" class="headerlink" title="（3）时钟同步"></a>（3）时钟同步</h4><p>ubuntu默认有时钟同步，与ubuntu官方指定的时钟服务器同步，前提是可以连接广域网。<br>如果只连接局域网，需要做时钟同步。<br>因为我们当前连接了广域网，所以时钟同步不进行额外操作了。</p><h4 id="（4）关闭防火墙"><a href="#（4）关闭防火墙" class="headerlink" title="（4）关闭防火墙"></a>（4）关闭防火墙</h4><p>因为Hadoop集群的网络是作为内部总线使用，为了防止因触发防火墙的规则造成的数据中流中断，必须关闭防火墙。<br>除指定的安全策略外，所有的安全内容必须全部关闭。<br>ubuntu的防火墙默认是关闭的。<br>检查防火墙状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ufw status</span><br></pre></td></tr></table></figure><p>在所有节点上检查防火墙状态：<br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/97c30905e7a4e7dd2683b2842b8dcfe0a50352ddf790312ad8199fe146c544a6.png" alt="图 5"><br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/d583796ef508a0653fc6a6828ae6a5287a25010f575f28e4373e60a14fe172f6.png" alt="图 6"><br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/40c34d64660617b0fa6791813b86818cb97bf9c26db7c76d8e4a328e6ff06cc2.png" alt="图 7"><br>当前所有节点防火墙都是关闭状态。<br>如果是开启状态，需要先关闭防火墙，然后disable防火墙。</p><h3 id="2）软件依赖"><a href="#2）软件依赖" class="headerlink" title="2）软件依赖"></a>2）软件依赖</h3><p>spark：<br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/8ecc94ac15ae31ed6be04c37649c3b8e3085df7862cf5dce772afa3a9d10acf6.png" alt="图 8"><br><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/44c47cd5c5a945b449d56a1ee442381a0bc8d68bcf566b0adfd92cb6547a65e4.png" alt="图 9">  </p><p>spark选最新版或最新稳定版，都需要Hadoop3.3以上版本</p><p><img src="/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/cfddfb635603373dcb0cef7f40318c85e337d5533d61ae1567cf263b77137086.png" alt="图 10"><br>Hadoop最新稳定版是3.3.6，再查找依赖的Java版本。<br>Java8是全功能，Java11只能运行时使用，所以选择Java8.</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/%E5%AD%A6%E4%B9%A0/">学习</category>
      
      
      <category domain="http://example.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</category>
      
      
      <comments>http://example.com/2024/11/04/%E5%A4%A7%E6%95%B0%E6%8D%AE-1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Markdown</title>
      <link>http://example.com/2024/10/28/Markdown/</link>
      <guid>http://example.com/2024/10/28/Markdown/</guid>
      <pubDate>Mon, 28 Oct 2024 02:23:55 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;Markdown的使用&quot;&gt;&lt;a href=&quot;#Markdown的使用&quot; class=&quot;headerlink&quot; title=&quot;Markdown的使用&quot;&gt;&lt;/a&gt;Markdown的使用&lt;/h1&gt;&lt;h2 id=&quot;1-标题编辑&quot;&gt;&lt;a href=&quot;#1-标题编辑&quot; class=&quot;headerlink&quot; title=&quot;1.标题编辑&quot;&gt;&lt;/a&gt;1.标题编辑&lt;/h2&gt;&lt;p&gt;Markdown语言中标题使用#来标记，可以表示1~6级标题，随着#增多标题逐渐缩小，注意要在#号后面需要加一个空格。  &lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<h1 id="Markdown的使用"><a href="#Markdown的使用" class="headerlink" title="Markdown的使用"></a>Markdown的使用</h1><h2 id="1-标题编辑"><a href="#1-标题编辑" class="headerlink" title="1.标题编辑"></a>1.标题编辑</h2><p>Markdown语言中标题使用#来标记，可以表示1~6级标题，随着#增多标题逐渐缩小，注意要在#号后面需要加一个空格。  </p><span id="more"></span><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 1级标题  </span><br><span class="line">## 2级标题  </span><br><span class="line">### 3级标题  </span><br><span class="line">#### 4级标题  </span><br><span class="line">##### 5级标题  </span><br><span class="line">###### 6级标题</span><br></pre></td></tr></table></figure><p>结果如下：  </p><h1 id="1级标题"><a href="#1级标题" class="headerlink" title="1级标题"></a>1级标题</h1><h2 id="2级标题"><a href="#2级标题" class="headerlink" title="2级标题"></a>2级标题</h2><h3 id="3级标题"><a href="#3级标题" class="headerlink" title="3级标题"></a>3级标题</h3><h4 id="4级标题"><a href="#4级标题" class="headerlink" title="4级标题"></a>4级标题</h4><h5 id="5级标题"><a href="#5级标题" class="headerlink" title="5级标题"></a>5级标题</h5><h6 id="6级标题"><a href="#6级标题" class="headerlink" title="6级标题"></a>6级标题</h6><h2 id="2-字体"><a href="#2-字体" class="headerlink" title="2.字体"></a>2.字体</h2><p>在Markdown中使用*或者_来改变字体，一个是斜体，两个是粗体，三个是粗斜体。  </p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="emphasis">*这是斜体*</span>  </span><br><span class="line"><span class="emphasis">_这是斜体_</span>  </span><br><span class="line"><span class="strong">**这是粗体**</span>  </span><br><span class="line"><span class="strong">__这是粗体__</span>  </span><br><span class="line"><span class="strong">**<span class="emphasis">*这是粗斜体*</span>**</span>  </span><br><span class="line"><span class="strong">__<span class="emphasis">_这是粗斜体_</span>__</span>  </span><br></pre></td></tr></table></figure><p>结果如下：<br><em>这是斜体</em><br><em>这是斜体</em><br><strong>这是粗体</strong><br><strong>这是粗体</strong><br><em><strong>这是粗斜体</strong></em><br><em><strong>这是粗斜体</strong></em>  </p><h2 id="3-换行"><a href="#3-换行" class="headerlink" title="3.换行"></a>3.换行</h2><p>Markdown中换行的方法有很多种：  </p><ul><li>在句子后面加两个空格。</li><li>两句话中间加一个空行</li><li>如果你在编辑的时候，想让一行文字在显示的时候换行，就在中间加&lt;br&#x2F;&gt;</li></ul><p>不过在我学习的时候发现下某些情况下，在句子后面加两个空格并不能换行，遇到这种情况在中间加一个空行就可以了。</p><h2 id="4-代码块"><a href="#4-代码块" class="headerlink" title="4.代码块"></a>4.代码块</h2><p>对于计算机专业的人来说，少不了与各种代码、命令行接触，这个时候Markdown的代码块功能就很有用了。  </p><h3 id="4-1整段代码块"><a href="#4-1整段代码块" class="headerlink" title="4.1整段代码块"></a>4.1整段代码块</h3><p>整段代码块通过两行 &#96;&#96;&#96; 符号框出，如果你写的代码是某种语言，那么可以在第一行末尾加上这个语言的名字，代码块内的代码就会执行对应的高亮语法，例如python：</p><p>`&#96;&#96;python<br>print(‘Hello World!’)<br>`&#96;&#96;<br>效果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Hello World!&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="4-2行内代码"><a href="#4-2行内代码" class="headerlink" title="4.2行内代码"></a>4.2行内代码</h3><p>正文中的代码，则通过输入&#96;&#96; 框出<br>`Hello&#96; World!<br>效果如下：</p><p><code>Hello</code> World! </p><h2 id="5-列表"><a href="#5-列表" class="headerlink" title="5.列表"></a>5.列表</h2><h3 id="5-1无序列表"><a href="#5-1无序列表" class="headerlink" title="5.1无序列表"></a>5.1无序列表</h3><ul><li>无序列表，使用*、+、-，再加一个空格作为列表的标记</li><li>有序列表，使用数字并加上.号，再加一个空格作为列表的标记<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">*</span> 无序列表 1</span><br><span class="line"><span class="bullet">+</span> 无序列表 2</span><br><span class="line"><span class="bullet">-</span> 无序列表 3</span><br><span class="line"></span><br><span class="line"><span class="bullet">1.</span> 有序列表 1</span><br><span class="line"><span class="bullet">2.</span> 有序列表 2</span><br><span class="line"><span class="bullet">3.</span> 有序列表 3</span><br></pre></td></tr></table></figure>效果如下：</li><li>无序列表 1</li></ul><ul><li>无序列表 2</li></ul><ul><li>无序列表 3</li></ul><ol><li>有序列表 1</li><li>有序列表 2</li><li>有序列表 3</li></ol><p>如果想要控制列表的层级，则需要在列表符号前使用Tab</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">+</span> 无序列表 1</span><br><span class="line"><span class="bullet">+</span> 无序列表 2</span><br><span class="line"><span class="bullet">    +</span> 无序列表 2.1</span><br><span class="line"><span class="bullet">    +</span> 无序列表 2.2</span><br><span class="line"></span><br><span class="line"><span class="bullet">1.</span> 有序列表 1</span><br><span class="line"><span class="code">    1.1 有序列表 1.1</span></span><br><span class="line"><span class="code">2. 有序列表 2</span></span><br><span class="line"><span class="code">    2.1 有序列表 2.1</span></span><br></pre></td></tr></table></figure><p>效果如下：</p><ul><li>无序列表 1</li><li>无序列表 2<ul><li>无序列表 2.1</li><li>无序列表 2.2</li></ul></li></ul><ol><li>有序列表 1<br> 1.1 有序列表 1.1</li><li>有序列表 2<br> 2.1 有序列表 2.1</li></ol><h2 id="6-引用"><a href="#6-引用" class="headerlink" title="6.引用"></a>6.引用</h2><p>Markdown 中引用通过符号 &gt; 来实现。&gt; 符号后的空格，可有可无。<br>在引用的区块内，允许换行存在，换行并不会终止引用的区块。如果要结束引用，需要一行空白行，来结束引用的区块。<br>代码：  </p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;这是一个引用</span><br></pre></td></tr></table></figure><p>效果如下：</p><blockquote><p>这是一个引用</p></blockquote><p>此外引用还可以嵌套<br>代码：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;这是一个引用：</span><br><span class="line">&gt;&gt;这是一个引用的引用</span><br><span class="line">&gt;&gt;&gt;这是一个引用的引用的引用</span><br></pre></td></tr></table></figure><blockquote><p>这是一个引用：</p><blockquote><p>这是一个引用的引用</p><blockquote><p>这是一个引用的引用的引用</p></blockquote></blockquote></blockquote><p>理论上引用可以一直嵌套下去，不过没什么用罢了。</p><h2 id="7-链接"><a href="#7-链接" class="headerlink" title="7.链接"></a>7.链接</h2><p>代码：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">链接名称</span>](<span class="link">链接地址</span>)</span><br><span class="line">或</span><br><span class="line">[链接名称]</span><br><span class="line">&lt;链接地址&gt;</span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">百度</span>](<span class="link">https://www.baidu.com/</span>)  </span><br><span class="line"><span class="language-xml">&lt;https://www.baidu.com/&gt;</span></span><br></pre></td></tr></table></figure><p><a href="https://www.baidu.com/">百度</a><br><a href="https://www.baidu.com/">https://www.baidu.com/</a></p><h2 id="8-图片"><a href="#8-图片" class="headerlink" title="8.图片"></a>8.图片</h2><p>Markdown中插入图片的方式是：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">![<span class="string">图片描述，可写可不写，但是中括号要有</span>](<span class="link">图片地址，本地链接或者URL地址。</span>)</span><br><span class="line">示例：</span><br><span class="line">![<span class="string">ikun</span>](<span class="link">Markdown/ikun.png</span>)</span><br></pre></td></tr></table></figure><p>效果如下：<br><img src="/2024/10/28/Markdown/ikun.png" alt="ikun"><br>直接使用Markdown修改图片的方法不知道为什么没成功，可以使用html的&lt;img&gt;语法来控制图片的大小，示例：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">方法1：设置图片的宽和高像素值： <span class="language-xml"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;图片路径&quot;</span> <span class="attr">width</span> = <span class="string">300</span> <span class="attr">height</span> = <span class="string">200</span>&gt;</span></span></span><br><span class="line">方法2：设置缩放的比例：<span class="language-xml"><span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">&quot;图片路径&quot;</span> <span class="attr">width</span> = <span class="string">60%</span>&gt;</span></span></span><br></pre></td></tr></table></figure><h2 id="9-分割线"><a href="#9-分割线" class="headerlink" title="9.分割线"></a>9.分割线</h2><p>Markdown中给出了多种分割线的样式，我们可以使用分割线让文章结构更加的清晰。<br>分割线的使用，可以在一行中用三个-或*来建立一个分割线，但是注意：在分割线的上面空一行！！！</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">分割线：</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"><span class="strong">***</span></span><br><span class="line"><span class="strong">- - -</span></span><br><span class="line"><span class="strong">* * <span class="emphasis">*</span></span></span><br></pre></td></tr></table></figure><p>分割线：</p><hr><hr><hr><hr><p>注意：写分割线前，要空一行之后写，否则会导致前一行字体放大。</p>]]></content:encoded>
      
      
      <category domain="http://example.com/categories/%E5%AD%A6%E4%B9%A0/">学习</category>
      
      
      <category domain="http://example.com/tags/Markdown%E8%AF%AD%E6%B3%95/">Markdown语法</category>
      
      
      <comments>http://example.com/2024/10/28/Markdown/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Hello World</title>
      <link>http://example.com/2024/10/16/hello-world/</link>
      <guid>http://example.com/2024/10/16/hello-world/</guid>
      <pubDate>Wed, 16 Oct 2024 04:08:20 GMT</pubDate>
      
      <description>&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;&lt;h3 id=&quot;Create-a-new-post&quot;&gt;&lt;a href=&quot;#Create-a-new-post&quot; class=&quot;headerlink&quot; title=&quot;Create a new post&quot;&gt;&lt;/a&gt;Create a new post&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ hexo new &lt;span class=&quot;string&quot;&gt;&amp;quot;My New Post&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><span id="more"></span><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content:encoded>
      
      
      
      
      <comments>http://example.com/2024/10/16/hello-world/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
